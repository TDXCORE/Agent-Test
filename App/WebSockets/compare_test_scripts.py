"""
üîç COMPARADOR DE SCRIPTS DE TESTING
==================================
Script para comparar las funcionalidades entre el script original
y el script enhanced de testing WebSocket.
"""

import os
import sys
from pathlib import Path

def print_header(title: str):
    """Imprime un header formateado."""
    print("\n" + "=" * 80)
    print(f"üîç {title}")
    print("=" * 80)

def print_section(title: str):
    """Imprime una secci√≥n formateada."""
    print(f"\nüìã {title}")
    print("-" * 60)

def analyze_file(file_path: str):
    """Analiza un archivo y extrae m√©tricas b√°sicas."""
    if not os.path.exists(file_path):
        return None
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    
    # Contar diferentes elementos
    classes = len([line for line in lines if line.strip().startswith('class ')])
    functions = len([line for line in lines if line.strip().startswith('def ')])
    async_functions = len([line for line in lines if 'async def' in line])
    imports = len([line for line in lines if line.strip().startswith('import ') or line.strip().startswith('from ')])
    comments = len([line for line in lines if line.strip().startswith('#')])
    docstrings = content.count('"""')
    
    # Buscar funcionalidades espec√≠ficas
    has_logging = 'logging' in content
    has_traceback = 'traceback' in content
    has_dataclass = '@dataclass' in content
    has_retry_logic = 'retry' in content.lower()
    has_validation = 'validation' in content.lower()
    has_metrics = 'metrics' in content.lower()
    
    return {
        'file_size': len(content),
        'lines': len(lines),
        'classes': classes,
        'functions': functions,
        'async_functions': async_functions,
        'imports': imports,
        'comments': comments,
        'docstrings': docstrings // 2,  # Dividir por 2 porque cada docstring tiene apertura y cierre
        'has_logging': has_logging,
        'has_traceback': has_traceback,
        'has_dataclass': has_dataclass,
        'has_retry_logic': has_retry_logic,
        'has_validation': has_validation,
        'has_metrics': has_metrics
    }

def compare_scripts():
    """Compara los dos scripts de testing."""
    print_header("COMPARACI√ìN DE SCRIPTS DE TESTING WEBSOCKET")
    
    # Rutas de los archivos
    original_path = "App/WebSockets/test_new_handlers.py"
    enhanced_path = "App/WebSockets/test_new_handlers_enhanced.py"
    
    # Analizar archivos
    original_stats = analyze_file(original_path)
    enhanced_stats = analyze_file(enhanced_path)
    
    if not original_stats:
        print(f"‚ùå No se pudo encontrar el archivo original: {original_path}")
        return
    
    if not enhanced_stats:
        print(f"‚ùå No se pudo encontrar el archivo enhanced: {enhanced_path}")
        return
    
    print_section("M√âTRICAS B√ÅSICAS")
    
    metrics = [
        ("Tama√±o del archivo (caracteres)", "file_size"),
        ("L√≠neas de c√≥digo", "lines"),
        ("Clases definidas", "classes"),
        ("Funciones totales", "functions"),
        ("Funciones async", "async_functions"),
        ("Imports", "imports"),
        ("Comentarios", "comments"),
        ("Docstrings", "docstrings")
    ]
    
    print(f"{'M√©trica':<35} {'Original':<15} {'Enhanced':<15} {'Diferencia':<15}")
    print("-" * 80)
    
    for metric_name, metric_key in metrics:
        original_val = original_stats[metric_key]
        enhanced_val = enhanced_stats[metric_key]
        diff = enhanced_val - original_val
        diff_str = f"+{diff}" if diff > 0 else str(diff)
        
        print(f"{metric_name:<35} {original_val:<15} {enhanced_val:<15} {diff_str:<15}")
    
    print_section("FUNCIONALIDADES AVANZADAS")
    
    features = [
        ("Sistema de Logging", "has_logging"),
        ("Stack Traces", "has_traceback"),
        ("Dataclasses", "has_dataclass"),
        ("L√≥gica de Retry", "has_retry_logic"),
        ("Validaci√≥n de Datos", "has_validation"),
        ("M√©tricas Avanzadas", "has_metrics")
    ]
    
    print(f"{'Funcionalidad':<25} {'Original':<15} {'Enhanced':<15}")
    print("-" * 55)
    
    for feature_name, feature_key in features:
        original_has = "‚úÖ" if original_stats[feature_key] else "‚ùå"
        enhanced_has = "‚úÖ" if enhanced_stats[feature_key] else "‚ùå"
        
        print(f"{feature_name:<25} {original_has:<15} {enhanced_has:<15}")
    
    print_section("NUEVAS FUNCIONALIDADES EN ENHANCED")
    
    new_features = [
        "üöÄ Logging detallado con timestamps precisos",
        "üîç Stack traces completos para errores",
        "üìä M√©tricas avanzadas de rendimiento",
        "üåê Informaci√≥n detallada de conexi√≥n WebSocket",
        "üíæ Guardado autom√°tico de logs en archivos",
        "üéØ Validaci√≥n de campos esperados vs recibidos",
        "üìà Scores de validaci√≥n de datos (0-100%)",
        "üîÑ Retry autom√°tico con backoff exponencial",
        "üñ•Ô∏è Informaci√≥n completa del sistema",
        "üìã An√°lisis detallado de errores con categorizaci√≥n",
        "‚è±Ô∏è Medici√≥n de latencia de red vs tiempo de servidor",
        "üíª Monitoreo de uso de memoria y CPU",
        "üîó Estado detallado de conexiones WebSocket",
        "üìÅ Organizaci√≥n autom√°tica de logs por timestamp"
    ]
    
    for feature in new_features:
        print(f"  {feature}")
    
    print_section("RECOMENDACIONES DE USO")
    
    recommendations = [
        ("üîß Desarrollo y debugging", "Enhanced", "M√°s informaci√≥n para identificar problemas"),
        ("üöÄ Testing r√°pido", "Original", "M√°s simple y directo"),
        ("üìä An√°lisis de rendimiento", "Enhanced", "M√©tricas detalladas disponibles"),
        ("üêõ Soluci√≥n de problemas", "Enhanced", "Stack traces y logging completo"),
        ("üìà Monitoreo de producci√≥n", "Enhanced", "Logs persistentes y m√©tricas"),
        ("‚úÖ Validaci√≥n b√°sica", "Original", "Suficiente para casos simples"),
        ("üîç Investigaci√≥n de errores", "Enhanced", "Informaci√≥n completa del contexto"),
        ("‚ö° Ejecuci√≥n automatizada", "Ambos", "Ambos soportan ejecuci√≥n autom√°tica")
    ]
    
    print(f"{'Caso de Uso':<30} {'Recomendado':<15} {'Raz√≥n':<35}")
    print("-" * 80)
    
    for use_case, recommended, reason in recommendations:
        print(f"{use_case:<30} {recommended:<15} {reason:<35}")
    
    print_section("COMANDOS DE EJECUCI√ìN")
    
    print("üìù Script Original:")
    print("   python App/WebSockets/test_new_handlers.py")
    print()
    print("üöÄ Script Enhanced:")
    print("   python App/WebSockets/test_new_handlers_enhanced.py")
    print()
    print("üìÅ Logs Enhanced se guardan en:")
    print("   App/WebSockets/logs/websocket_test_YYYYMMDD_HHMMSS.log")
    
    print_section("PR√ìXIMOS PASOS")
    
    next_steps = [
        "1. üß™ Ejecutar ambos scripts para comparar resultados",
        "2. üìä Revisar los logs detallados del script enhanced",
        "3. üîç Usar enhanced para debugging de problemas espec√≠ficos",
        "4. üìà Implementar m√©tricas en dashboard de monitoreo",
        "5. üîÑ Configurar ejecuci√≥n autom√°tica en CI/CD",
        "6. üìù Documentar patrones de errores encontrados",
        "7. üéØ Optimizar funciones basado en m√©tricas de rendimiento"
    ]
    
    for step in next_steps:
        print(f"  {step}")
    
    print("\n" + "=" * 80)
    print("‚úÖ Comparaci√≥n completada. Ambos scripts est√°n listos para usar.")
    print("üìã Consulta README_ENHANCED_TESTING.md para m√°s detalles.")
    print("=" * 80)

if __name__ == "__main__":
    try:
        compare_scripts()
    except Exception as e:
        print(f"‚ùå Error durante la comparaci√≥n: {str(e)}")
        import traceback
        traceback.print_exc()
